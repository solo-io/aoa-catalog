
apiVersion: v1
kind: Namespace
metadata:
  name: ns-14
  labels:
    seed: "1695848925151071000"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ancient-meadow
  namespace: ns-14
  labels:
    app: ancient-meadow
    tier: "1"
    seed: "1695848925151071000"
---
apiVersion: v1
kind: Service
metadata:
  name: ancient-meadow
  namespace: ns-14
  labels:
    app: ancient-meadow
    tier: "1"
    seed: "1695848925151071000"
spec:
  selector:
    app: ancient-meadow
  ports:
  - name: http
    protocol: TCP
    port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ancient-meadow-v1
  namespace: ns-14
  labels:
    app: ancient-meadow
    version: v1
    tier: "1"
    seed: "1695848925151071000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: ancient-meadow
        version: v1
  template:
    metadata:
      labels:
        app: ancient-meadow
        version: v1
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: ancient-meadow
      containers:
      - name: ancient-meadow
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "ancient-meadow-v1"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From ancient-meadow (v1)!"
        - name: "UPSTREAM_URIS"
          value: "http://small-resonance.ns-14.svc.cluster.local.:8080"
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "5ms"
        - name: "TIMING_90_PERCENTILE"
          value: "10ms"
        - name: "TIMING_99_PERCENTILE"
          value: "20ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: dry-lake
  namespace: ns-14
  labels:
    app: dry-lake
    tier: "5"
    seed: "1695848925151071000"
---
apiVersion: v1
kind: Service
metadata:
  name: dry-lake
  namespace: ns-14
  labels:
    app: dry-lake
    tier: "5"
    seed: "1695848925151071000"
spec:
  selector:
    app: dry-lake
  ports:
  - name: http
    protocol: TCP
    port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dry-lake-v1
  namespace: ns-14
  labels:
    app: dry-lake
    version: v1
    tier: "5"
    seed: "1695848925151071000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: dry-lake
        version: v1
  template:
    metadata:
      labels:
        app: dry-lake
        version: v1
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: dry-lake
      containers:
      - name: dry-lake
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "dry-lake-v1"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From dry-lake (v1)!"
        - name: "UPSTREAM_URIS"
          value: ""
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "5ms"
        - name: "TIMING_90_PERCENTILE"
          value: "10ms"
        - name: "TIMING_99_PERCENTILE"
          value: "20ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: frosty-sunset
  namespace: ns-14
  labels:
    app: frosty-sunset
    tier: "4"
    seed: "1695848925151071000"
---
apiVersion: v1
kind: Service
metadata:
  name: frosty-sunset
  namespace: ns-14
  labels:
    app: frosty-sunset
    tier: "4"
    seed: "1695848925151071000"
spec:
  selector:
    app: frosty-sunset
  ports:
  - name: http
    protocol: TCP
    port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frosty-sunset-v1
  namespace: ns-14
  labels:
    app: frosty-sunset
    version: v1
    tier: "4"
    seed: "1695848925151071000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: frosty-sunset
        version: v1
  template:
    metadata:
      labels:
        app: frosty-sunset
        version: v1
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: frosty-sunset
      containers:
      - name: frosty-sunset
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "frosty-sunset-v1"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From frosty-sunset (v1)!"
        - name: "UPSTREAM_URIS"
          value: ""
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "5ms"
        - name: "TIMING_90_PERCENTILE"
          value: "10ms"
        - name: "TIMING_99_PERCENTILE"
          value: "20ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: small-resonance
  namespace: ns-14
  labels:
    app: small-resonance
    tier: "2"
    seed: "1695848925151071000"
---
apiVersion: v1
kind: Service
metadata:
  name: small-resonance
  namespace: ns-14
  labels:
    app: small-resonance
    tier: "2"
    seed: "1695848925151071000"
spec:
  selector:
    app: small-resonance
  ports:
  - name: http
    protocol: TCP
    port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: small-resonance-v1
  namespace: ns-14
  labels:
    app: small-resonance
    version: v1
    tier: "2"
    seed: "1695848925151071000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: small-resonance
        version: v1
  template:
    metadata:
      labels:
        app: small-resonance
        version: v1
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: small-resonance
      containers:
      - name: small-resonance
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "small-resonance-v1"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From small-resonance (v1)!"
        - name: "UPSTREAM_URIS"
          value: "http://white-bird.ns-14.svc.cluster.local.:8080,http://snowy-fog.ns-14.svc.cluster.local.:8080"
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "5ms"
        - name: "TIMING_90_PERCENTILE"
          value: "10ms"
        - name: "TIMING_99_PERCENTILE"
          value: "20ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: snowy-fog
  namespace: ns-14
  labels:
    app: snowy-fog
    tier: "3"
    seed: "1695848925151071000"
---
apiVersion: v1
kind: Service
metadata:
  name: snowy-fog
  namespace: ns-14
  labels:
    app: snowy-fog
    tier: "3"
    seed: "1695848925151071000"
spec:
  selector:
    app: snowy-fog
  ports:
  - name: http
    protocol: TCP
    port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: snowy-fog-v1
  namespace: ns-14
  labels:
    app: snowy-fog
    version: v1
    tier: "3"
    seed: "1695848925151071000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: snowy-fog
        version: v1
  template:
    metadata:
      labels:
        app: snowy-fog
        version: v1
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: snowy-fog
      containers:
      - name: snowy-fog
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "snowy-fog-v1"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From snowy-fog (v1)!"
        - name: "UPSTREAM_URIS"
          value: "http://frosty-sunset.ns-14.svc.cluster.local.:8080"
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "5ms"
        - name: "TIMING_90_PERCENTILE"
          value: "10ms"
        - name: "TIMING_99_PERCENTILE"
          value: "20ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: white-bird
  namespace: ns-14
  labels:
    app: white-bird
    tier: "3"
    seed: "1695848925151071000"
---
apiVersion: v1
kind: Service
metadata:
  name: white-bird
  namespace: ns-14
  labels:
    app: white-bird
    tier: "3"
    seed: "1695848925151071000"
spec:
  selector:
    app: white-bird
  ports:
  - name: http
    protocol: TCP
    port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: white-bird-v1
  namespace: ns-14
  labels:
    app: white-bird
    version: v1
    tier: "3"
    seed: "1695848925151071000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: white-bird
        version: v1
  template:
    metadata:
      labels:
        app: white-bird
        version: v1
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: white-bird
      containers:
      - name: white-bird
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "white-bird-v1"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From white-bird (v1)!"
        - name: "UPSTREAM_URIS"
          value: ""
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "5ms"
        - name: "TIMING_90_PERCENTILE"
          value: "10ms"
        - name: "TIMING_99_PERCENTILE"
          value: "20ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---