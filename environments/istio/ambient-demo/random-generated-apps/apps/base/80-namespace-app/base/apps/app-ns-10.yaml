
apiVersion: v1
kind: Namespace
metadata:
  name: ns-10
  labels:
    seed: "1695851633735537000"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: black-rain
  namespace: ns-10
  labels:
    app: black-rain
    tier: "2"
    seed: "1695851633735537000"
---
apiVersion: v1
kind: Service
metadata:
  name: black-rain
  namespace: ns-10
  labels:
    app: black-rain
    tier: "2"
    seed: "1695851633735537000"
spec:
  selector:
    app: black-rain
  ports:
  - name: http
    protocol: TCP
    port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: black-rain-v1
  namespace: ns-10
  labels:
    app: black-rain
    version: v1
    tier: "2"
    seed: "1695851633735537000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: black-rain
        version: v1
  template:
    metadata:
      labels:
        app: black-rain
        version: v1
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: black-rain
      containers:
      - name: black-rain
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "black-rain-v1"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From black-rain (v1)!"
        - name: "UPSTREAM_URIS"
          value: ""
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "0ms"
        - name: "TIMING_90_PERCENTILE"
          value: "0ms"
        - name: "TIMING_99_PERCENTILE"
          value: "0ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        - name: "HTTP_SERVER_KEEP_ALIVES"
          value: "true"
        - name: "HTTP_CLIENT_KEEP_ALIVES"
          value: "true"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: black-rain-v2
  namespace: ns-10
  labels:
    app: black-rain
    version: v2
    tier: "2"
    seed: "1695851633735537000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: black-rain
        version: v2
  template:
    metadata:
      labels:
        app: black-rain
        version: v2
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: black-rain
      containers:
      - name: black-rain
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "black-rain-v2"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From black-rain (v2)!"
        - name: "UPSTREAM_URIS"
          value: ""
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "0ms"
        - name: "TIMING_90_PERCENTILE"
          value: "0ms"
        - name: "TIMING_99_PERCENTILE"
          value: "0ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        - name: "HTTP_SERVER_KEEP_ALIVES"
          value: "true"
        - name: "HTTP_CLIENT_KEEP_ALIVES"
          value: "true"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: still-haze
  namespace: ns-10
  labels:
    app: still-haze
    tier: "1"
    seed: "1695851633735537000"
---
apiVersion: v1
kind: Service
metadata:
  name: still-haze
  namespace: ns-10
  labels:
    app: still-haze
    tier: "1"
    seed: "1695851633735537000"
spec:
  selector:
    app: still-haze
  ports:
  - name: http
    protocol: TCP
    port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: still-haze-v1
  namespace: ns-10
  labels:
    app: still-haze
    version: v1
    tier: "1"
    seed: "1695851633735537000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: still-haze
        version: v1
  template:
    metadata:
      labels:
        app: still-haze
        version: v1
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: still-haze
      containers:
      - name: still-haze
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "still-haze-v1"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From still-haze (v1)!"
        - name: "UPSTREAM_URIS"
          value: "http://wispy-snow.ns-10.svc.cluster.local.:8080,http://black-rain.ns-10.svc.cluster.local.:8080"
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "0ms"
        - name: "TIMING_90_PERCENTILE"
          value: "0ms"
        - name: "TIMING_99_PERCENTILE"
          value: "0ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        - name: "HTTP_SERVER_KEEP_ALIVES"
          value: "true"
        - name: "HTTP_CLIENT_KEEP_ALIVES"
          value: "true"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: still-haze-v2
  namespace: ns-10
  labels:
    app: still-haze
    version: v2
    tier: "1"
    seed: "1695851633735537000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: still-haze
        version: v2
  template:
    metadata:
      labels:
        app: still-haze
        version: v2
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: still-haze
      containers:
      - name: still-haze
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "still-haze-v2"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From still-haze (v2)!"
        - name: "UPSTREAM_URIS"
          value: "http://wispy-snow.ns-10.svc.cluster.local.:8080,http://black-rain.ns-10.svc.cluster.local.:8080"
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "0ms"
        - name: "TIMING_90_PERCENTILE"
          value: "0ms"
        - name: "TIMING_99_PERCENTILE"
          value: "0ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        - name: "HTTP_SERVER_KEEP_ALIVES"
          value: "true"
        - name: "HTTP_CLIENT_KEEP_ALIVES"
          value: "true"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: wispy-snow
  namespace: ns-10
  labels:
    app: wispy-snow
    tier: "2"
    seed: "1695851633735537000"
---
apiVersion: v1
kind: Service
metadata:
  name: wispy-snow
  namespace: ns-10
  labels:
    app: wispy-snow
    tier: "2"
    seed: "1695851633735537000"
spec:
  selector:
    app: wispy-snow
  ports:
  - name: http
    protocol: TCP
    port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wispy-snow-v1
  namespace: ns-10
  labels:
    app: wispy-snow
    version: v1
    tier: "2"
    seed: "1695851633735537000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: wispy-snow
        version: v1
  template:
    metadata:
      labels:
        app: wispy-snow
        version: v1
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: wispy-snow
      containers:
      - name: wispy-snow
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "wispy-snow-v1"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From wispy-snow (v1)!"
        - name: "UPSTREAM_URIS"
          value: ""
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "0ms"
        - name: "TIMING_90_PERCENTILE"
          value: "0ms"
        - name: "TIMING_99_PERCENTILE"
          value: "0ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        - name: "HTTP_SERVER_KEEP_ALIVES"
          value: "true"
        - name: "HTTP_CLIENT_KEEP_ALIVES"
          value: "true"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wispy-snow-v2
  namespace: ns-10
  labels:
    app: wispy-snow
    version: v2
    tier: "2"
    seed: "1695851633735537000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: wispy-snow
        version: v2
  template:
    metadata:
      labels:
        app: wispy-snow
        version: v2
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: wispy-snow
      containers:
      - name: wispy-snow
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "wispy-snow-v2"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From wispy-snow (v2)!"
        - name: "UPSTREAM_URIS"
          value: ""
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "0ms"
        - name: "TIMING_90_PERCENTILE"
          value: "0ms"
        - name: "TIMING_99_PERCENTILE"
          value: "0ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        - name: "HTTP_SERVER_KEEP_ALIVES"
          value: "true"
        - name: "HTTP_CLIENT_KEEP_ALIVES"
          value: "true"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wispy-snow-v3
  namespace: ns-10
  labels:
    app: wispy-snow
    version: v3
    tier: "2"
    seed: "1695851633735537000"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
        app: wispy-snow
        version: v3
  template:
    metadata:
      labels:
        app: wispy-snow
        version: v3
      annotations:
        sidecar.istio.io/proxyMemoryLimit: "1Gi"
        sidecar.istio.io/proxyCPULimit: "2"
        sidecar.istio.io/proxyMemory: "128Mi"
        sidecar.istio.io/proxyCPU: "100m"
    spec:
      serviceAccountName: wispy-snow
      containers:
      - name: wispy-snow
        image: ghcr.io/nmnellis/fake-service:v2
        ports:
        - containerPort: 8080
        securityContext:
          runAsUser: 1001
        env:
        - name: "LISTEN_ADDR"
          value: "0.0.0.0:8080"
        - name: "NAME"
          value: "wispy-snow-v3"
        - name: "SERVER_TYPE"
          value: "http"
        - name: "MESSAGE"
          value: "Hello From wispy-snow (v3)!"
        - name: "UPSTREAM_URIS"
          value: ""
        - name: "UPSTREAM_WORKERS"
          value: "10"
        - name: "TIMING_50_PERCENTILE"
          value: "0ms"
        - name: "TIMING_90_PERCENTILE"
          value: "0ms"
        - name: "TIMING_99_PERCENTILE"
          value: "0ms"
        - name: "HTTP_CLIENT_REQUEST_TIMEOUT"
          value: "30s"
        - name: "HTTP_SERVER_KEEP_ALIVES"
          value: "true"
        - name: "HTTP_CLIENT_KEEP_ALIVES"
          value: "true"
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
---